{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from src.utils.dataset import dataset_to_dataloaders, show_class_name, get_class_example_image\n",
    "from src.utils.visual import show_img, tensor_to_image, postprocess_image\n",
    "from src.utils.training import fit, test_model\n",
    "from src.models import download_model, HookedModel, load_model_weights_and_metrics, HookedModel_gen\n",
    "from src.deepdream import dream_process, dream_process_gen\n",
    "from src.utils.config import RESNET18_FULL, RESNET18_TRANSFER, RESNET34_FULL, RESNET34_TRANSFER, RESNET50_FULL, RESNET50_TRANSFER, RESNET18_TEST, DEFAULT_OUTPUT_PATH\n",
    "from src.utils.config import DREAM_CONFIG, BEETLE_DATASET, DEFAULT_TRAINING, DEFAULT_PLOTTING, JACKISET, MATHIAS_DATASET\n",
    "from src.utils.config import get_new_config, DEFAULT_IMG_PATH, DEFAULT_VIDEO_PATH, Config\n",
    "from src.utils.custom_types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import configuration dictionaries\n",
    "Things work a bit differently now. Below we import configuration dictionaries that define our model, dataset and training.\n",
    "\n",
    "These dictionaries are defined inside `src/utils/config.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config =BEETLE_DATASET\n",
    "model_config = RESNET34_FULL\n",
    "training_config = DEFAULT_TRAINING\n",
    "plot_config = DEFAULT_PLOTTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply transforms and get dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "data_loaders, dataset_sizes = dataset_to_dataloaders(dataset_config)\n",
    "iterable = iter(data_loaders['train'])\n",
    "images, labels = next(iterable)\n",
    "tensor_grid = make_grid(images, nrow=8)\n",
    "image_grid = postprocess_image(tensor_to_image(tensor_grid))\n",
    "show_img(image_grid, figsize=(20, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading {}'.format(model_config['model_architecture']))\n",
    "model = download_model(model_config, dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and or load classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "\n",
    "if load:\n",
    "    metrics, model_config, dataset_config, training_config = load_model_weights_and_metrics(model, model_config)\n",
    "    print((\"test accuracy = %.2f %%\" % training_config['train_info']['test_acc']))\n",
    "else:\n",
    "    metrics = fit(model, data_loaders, dataset_sizes,\n",
    "                  model_config, training_config, dataset_config, plot_config, \n",
    "                  clear='notebook', plot=True, save_interval=1)\n",
    "    acc = test_model(model, data_loaders['test'], training_config, model_config['device'])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models.resnet34(True).eval().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expose layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 1000\n",
    "gen = './output/GANs/current_best_v1/current_best_v1_gen.pt'\n",
    "mean_lat = './output/GANs/current_best_v1/current_best_v1_mean_std.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreamnet = HookedModel_gen(model,config.mean, config.std, gen, latent_dim)\n",
    "#_ = dreamnet.eval()\n",
    "#dreamnet.show_modules()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets dream!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose image\n",
    "\n",
    "You can see what a specific class's name is with the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_class_name(0, dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one takes a class label and returns an image instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_class_example_image(0, dataset_config)\n",
    "show_img(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose parameters and apply method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`out_info` is now a dictionary, and you can target modules in the model in a multitude of ways.\n",
    "\n",
    "`{'fc': None}`      targets the entire `fc` layer\n",
    "\n",
    "`{'fc': 1}`         targets class `1` in the `fc` layer\n",
    "\n",
    "`{'fc': [0,1,2]}`   targets classes `0`,`1`,`2` in the `fc` layer\n",
    "\n",
    "\n",
    "The same counts for 2d modules, such as `conv1`:\n",
    "\n",
    "`{'conv1': (5,5)}`          targets `(5,5)` in `conv1`\n",
    "\n",
    "`{'conv1': [(5,5), (2,2)]}`  targets `(5,5)` and `(2,2)` in `conv1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'input_img_path':  'data/beetles/images/achenium_humile/_0189_0.jpg',\n",
    "    'target_dict': {'fc': 55},\n",
    "    'num_iters': 40,\n",
    "    'levels': 5,\n",
    "    'ratio':1.3,\n",
    "    'lr': (0.5, 0.8),\n",
    "    'lr_mode':            'ratio',\n",
    "    #'smooth_const': 0,\n",
    "    'noise': 'uniform',\n",
    "    #'correlation' : 'gaussian',\n",
    "    #'correlation_std' : 1,\n",
    "    'target_shape': (200, 400),\n",
    "    #'gauss_filter' : (7, 7, 5, 5),\n",
    "    'show': True,\n",
    "    'output_img_path': None,\n",
    "    'video_path': None,\n",
    "    'scale_type' : 'image_pyramid',\n",
    "\n",
    "    'loss_type': 'mean',\n",
    "\n",
    "    'penalty':            False,\n",
    "    'penalty_loss_type':  'sum',\n",
    "    'penalty_function':   'relu',\n",
    "    'penalty_red':        'mean',\n",
    "}\n",
    "config.dream = get_new_config(params, DREAM_CONFIG)\n",
    "output_images = dream_process_gen(dreamnet, config, mean_lat)\n",
    "np.argmax(output_images[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(30,20))\n",
    "fig.set_facecolor('white')\n",
    "\n",
    "ax[0].plot(output_images[1].reshape(-1))\n",
    "ax[1].plot(output_images[2][-1].reshape(-1))\n",
    "#output_images[2]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfea30af7b705b6cd4564b1983153dbec880bd38f80a82b10c3349c4f80b4cbc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
